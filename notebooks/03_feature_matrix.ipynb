{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be5ed92f",
   "metadata": {},
   "source": [
    "# 07_feature_matrix + baseline model\n",
    "\n",
    "## Current “best” features (deduped) + Mutual Information (MI)\n",
    "1. is_international_user — 0.063161  \n",
    "2. uses_many_channels — 0.016385  \n",
    "3. industry — 0.011218  \n",
    "4. kyc_province — 0.006378  \n",
    "5. recent_amount_ratio — 0.005571  \n",
    "6. ratio_emt — 0.005094  \n",
    "7. amount_cv — 0.004436  \n",
    "8. debit_ratio — 0.004303  \n",
    "9. channel_entropy — 0.003901  \n",
    "10. total_amount_vs_finpeer — 0.003895  \n",
    "11. occupation — 0.003692  \n",
    "12. pct_history_before_intl — 0.003631  \n",
    "13. credit_ratio — 0.003352  \n",
    "14. cv_vs_peer_ratio — 0.003101  \n",
    "15. max_amount — 0.002908  \n",
    "\n",
    "## Goal of this notebook\n",
    "1) Load train/test customer + transaction splits  \n",
    "2) Merge feature tables from different notebooks into ONE feature matrix  \n",
    "3) Train baseline model (LogReg or LightGBM if available)  \n",
    "4) Evaluate ROC-AUC, PR-AUC, Top-K recall (more AML-relevant than threshold=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88429b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customers_train: (700, 18)\n",
      "customers_test : (150, 18)\n",
      "txns_train: (43004, 31)\n",
      "txns_test : (6939, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>birth_date</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_type</th>\n",
       "      <th>employee_count</th>\n",
       "      <th>established_date</th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>onboard_date</th>\n",
       "      <th>province</th>\n",
       "      <th>sales</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972-12-07</td>\n",
       "      <td>other</td>\n",
       "      <td>CA</td>\n",
       "      <td>SYNID0108676505</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>123875.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Married</td>\n",
       "      <td>SELF_EMPLOYED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2001-03-17</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1964-02-20</td>\n",
       "      <td>other</td>\n",
       "      <td>CA</td>\n",
       "      <td>SYNID0104294551</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Single</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2010-06-12</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986-04-08</td>\n",
       "      <td>MONTREAL</td>\n",
       "      <td>CA</td>\n",
       "      <td>SYNID0108958094</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2016-03-25</td>\n",
       "      <td>QC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-04-08</td>\n",
       "      <td>KINGSTON</td>\n",
       "      <td>CA</td>\n",
       "      <td>SYNID0102414463</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Single</td>\n",
       "      <td>SELF_EMPLOYED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935-05-02</td>\n",
       "      <td>BRAMPTON</td>\n",
       "      <td>CA</td>\n",
       "      <td>SYNID0100000485</td>\n",
       "      <td>individual</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>19998.0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>1997-07-12</td>\n",
       "      <td>ON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   birth_date      city country      customer_id customer_type  \\\n",
       "0  1972-12-07     other      CA  SYNID0108676505    individual   \n",
       "1  1964-02-20     other      CA  SYNID0104294551    individual   \n",
       "2  1986-04-08  MONTREAL      CA  SYNID0108958094    individual   \n",
       "3  1999-04-08  KINGSTON      CA  SYNID0102414463    individual   \n",
       "4  1935-05-02  BRAMPTON      CA  SYNID0100000485    individual   \n",
       "\n",
       "   employee_count established_date  gender    income industry industry_code  \\\n",
       "0             NaN              NaN    MALE  123875.0  Unknown       Unknown   \n",
       "1             NaN              NaN  FEMALE       NaN  Unknown       Unknown   \n",
       "2             NaN              NaN    MALE       NaN  Unknown       Unknown   \n",
       "3             NaN              NaN  FEMALE       NaN  Unknown       Unknown   \n",
       "4             NaN              NaN  FEMALE   19998.0  Unknown       Unknown   \n",
       "\n",
       "  marital_status occupation_code occupation_title onboard_date province  \\\n",
       "0        Married   SELF_EMPLOYED          Unknown   2001-03-17  Unknown   \n",
       "1         Single         RETIRED          Unknown   2010-06-12  Unknown   \n",
       "2        Unknown           OTHER          Unknown   2016-03-25       QC   \n",
       "3         Single   SELF_EMPLOYED          Unknown   2021-08-17       ON   \n",
       "4        Widowed         RETIRED          Unknown   1997-07-12       ON   \n",
       "\n",
       "   sales  label  \n",
       "0    NaN    0.0  \n",
       "1    NaN    0.0  \n",
       "2    NaN    0.0  \n",
       "3    NaN    0.0  \n",
       "4    NaN    0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path.cwd().parents[0]\n",
    "PROCESSED = REPO_ROOT/\"data/processed\"\n",
    "INTERIM = REPO_ROOT/\"data/interim\"   # if you prefer interim outputs from feature notebooks\n",
    "\n",
    "# load training splits ONLY\n",
    "customers_train = pd.read_csv(PROCESSED/\"customers_train.csv\")\n",
    "customers_test  = pd.read_csv(PROCESSED/\"customers_test.csv\")\n",
    "\n",
    "txns_train = pd.read_csv(PROCESSED/\"transactions_train.csv\")\n",
    "txns_test  = pd.read_csv(PROCESSED/\"transactions_test.csv\")\n",
    "\n",
    "# parse datetime\n",
    "for df in [txns_train, txns_test]:\n",
    "    if \"transaction_datetime\" in df.columns:\n",
    "        df[\"transaction_datetime\"] = pd.to_datetime(df[\"transaction_datetime\"], errors=\"coerce\")\n",
    "\n",
    "print(\"customers_train:\", customers_train.shape)\n",
    "print(\"customers_test :\", customers_test.shape)\n",
    "print(\"txns_train:\", txns_train.shape)\n",
    "print(\"txns_test :\", txns_test.shape)\n",
    "\n",
    "customers_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70488974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN customers label counts:\n",
      "label\n",
      "0.0    693\n",
      "1.0      7\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TEST customers label counts:\n",
      "label\n",
      "0.0    149\n",
      "1.0      1\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def label_counts(df, name):\n",
    "    vc = df[\"label\"].value_counts(dropna=False)\n",
    "    print(f\"{name} label counts:\\n{vc}\\n\")\n",
    "\n",
    "label_counts(customers_train, \"TRAIN customers\")\n",
    "label_counts(customers_test,  \"TEST customers\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b17a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feat_train: (700, 62)\n",
      "feat_test : (150, 62)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>label</th>\n",
       "      <th>cash_txn_count</th>\n",
       "      <th>cash_txn_ratio</th>\n",
       "      <th>cash_amount</th>\n",
       "      <th>cash_amount_ratio</th>\n",
       "      <th>cash_amount_last30d</th>\n",
       "      <th>cash_recent_spike_ratio</th>\n",
       "      <th>cash_round_100_ratio</th>\n",
       "      <th>cash_round_1000_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>activity_burstiness</th>\n",
       "      <th>industry</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>occupation_title</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>province</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>gender</th>\n",
       "      <th>marital_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SYNID0108676505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>SELF_EMPLOYED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CA</td>\n",
       "      <td>other</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Married</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SYNID0104294551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016159</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>CA</td>\n",
       "      <td>other</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SYNID0108958094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890328</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>QC</td>\n",
       "      <td>CA</td>\n",
       "      <td>MONTREAL</td>\n",
       "      <td>MALE</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SYNID0102414463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.958290</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>SELF_EMPLOYED</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>KINGSTON</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SYNID0100000485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025</td>\n",
       "      <td>415.92</td>\n",
       "      <td>0.037841</td>\n",
       "      <td>415.92</td>\n",
       "      <td>4.159200e+11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156476</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>ON</td>\n",
       "      <td>CA</td>\n",
       "      <td>BRAMPTON</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>Widowed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_id  label  cash_txn_count  cash_txn_ratio  cash_amount  \\\n",
       "0  SYNID0108676505    0.0               0           0.000         0.00   \n",
       "1  SYNID0104294551    0.0               0           0.000         0.00   \n",
       "2  SYNID0108958094    0.0               0           0.000         0.00   \n",
       "3  SYNID0102414463    0.0               0           0.000         0.00   \n",
       "4  SYNID0100000485    0.0               1           0.025       415.92   \n",
       "\n",
       "   cash_amount_ratio  cash_amount_last30d  cash_recent_spike_ratio  \\\n",
       "0           0.000000                 0.00             1.000000e+00   \n",
       "1           0.000000                 0.00             1.000000e+00   \n",
       "2           0.000000                 0.00             1.000000e+00   \n",
       "3           0.000000                 0.00             1.000000e+00   \n",
       "4           0.037841               415.92             4.159200e+11   \n",
       "\n",
       "   cash_round_100_ratio  cash_round_1000_ratio  ...  activity_burstiness  \\\n",
       "0                   0.0                    0.0  ...             0.000000   \n",
       "1                   0.0                    0.0  ...             1.016159   \n",
       "2                   0.0                    0.0  ...             0.890328   \n",
       "3                   0.0                    0.0  ...             0.958290   \n",
       "4                   0.0                    0.0  ...             1.156476   \n",
       "\n",
       "   industry  industry_code  occupation_title  occupation_code  province  \\\n",
       "0   Unknown        Unknown           Unknown    SELF_EMPLOYED   Unknown   \n",
       "1   Unknown        Unknown           Unknown          RETIRED   Unknown   \n",
       "2   Unknown        Unknown           Unknown            OTHER        QC   \n",
       "3   Unknown        Unknown           Unknown    SELF_EMPLOYED        ON   \n",
       "4   Unknown        Unknown           Unknown          RETIRED        ON   \n",
       "\n",
       "   country      city  gender  marital_status  \n",
       "0       CA     other    MALE         Married  \n",
       "1       CA     other  FEMALE          Single  \n",
       "2       CA  MONTREAL    MALE         Unknown  \n",
       "3       CA  KINGSTON  FEMALE          Single  \n",
       "4       CA  BRAMPTON  FEMALE         Widowed  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EDIT THESE FILENAMES TO MATCH WHAT YOUR FEATURE NOTEBOOKS SAVE\n",
    "FEATURE_TABLES = {\n",
    "    \"cash\": {\n",
    "        \"train\": INTERIM/\"features_cash_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_cash_test.csv\",\n",
    "    },\n",
    "    \"wire\": {\n",
    "        \"train\": INTERIM/\"features_wire_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_wire_test.csv\",\n",
    "    },\n",
    "    \"emt\": {\n",
    "        \"train\": INTERIM/\"features_emt_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_emt_test.csv\",\n",
    "    },\n",
    "    \"geo\": {\n",
    "        \"train\": INTERIM/\"features_geo_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_geo_test.csv\",\n",
    "    },\n",
    "    \"behavioral\": {\n",
    "        \"train\": INTERIM/\"features_behavioral_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_behavioral_test.csv\",\n",
    "    },\n",
    "    \"profile\": {\n",
    "        \"train\": INTERIM/\"features_profile_train.csv\",\n",
    "        \"test\":  INTERIM/\"features_profile_test.csv\",\n",
    "    },\n",
    "}\n",
    "\n",
    "def load_feature_table(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, low_memory=False)\n",
    "    if \"customer_id\" not in df.columns:\n",
    "        raise ValueError(f\"{path} missing customer_id column\")\n",
    "    df = df.drop_duplicates(\"customer_id\")\n",
    "    return df\n",
    "\n",
    "def merge_feature_tables(base_customers: pd.DataFrame, split: str) -> pd.DataFrame:\n",
    "    out = base_customers[[\"customer_id\", \"label\"]].copy()\n",
    "    for name, paths in FEATURE_TABLES.items():\n",
    "        p = paths[split]\n",
    "        if not p.exists():\n",
    "            print(f\"[WARN] missing {name} {split}: {p}\")\n",
    "            continue\n",
    "        ft = load_feature_table(p)\n",
    "        out = out.merge(ft, on=\"customer_id\", how=\"left\", validate=\"1:1\")\n",
    "    return out\n",
    "\n",
    "feat_train = merge_feature_tables(customers_train, \"train\")\n",
    "feat_test  = merge_feature_tables(customers_test,  \"test\")\n",
    "\n",
    "print(\"feat_train:\", feat_train.shape)\n",
    "print(\"feat_test :\", feat_test.shape)\n",
    "\n",
    "feat_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e20ea57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_cols: 51\n",
      "cat_cols: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['industry',\n",
       "  'industry_code',\n",
       "  'occupation_title',\n",
       "  'occupation_code',\n",
       "  'province',\n",
       "  'country',\n",
       "  'city',\n",
       "  'gender',\n",
       "  'marital_status'],\n",
       " ['cash_txn_count',\n",
       "  'cash_txn_ratio',\n",
       "  'cash_amount',\n",
       "  'cash_amount_ratio',\n",
       "  'cash_amount_last30d',\n",
       "  'cash_recent_spike_ratio',\n",
       "  'cash_round_100_ratio',\n",
       "  'cash_round_1000_ratio',\n",
       "  'cash_cents_00_ratio',\n",
       "  'cash_burst_1h'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labeled only (your train/test splits should already be labeled, but keep safe)\n",
    "train_df = feat_train[feat_train[\"label\"].notna()].copy()\n",
    "test_df  = feat_test[feat_test[\"label\"].notna()].copy()\n",
    "\n",
    "y_train = train_df[\"label\"].astype(int)\n",
    "y_test  = test_df[\"label\"].astype(int)\n",
    "\n",
    "X_train = train_df.drop(columns=[\"customer_id\", \"label\"])\n",
    "X_test  = test_df.drop(columns=[\"customer_id\", \"label\"])\n",
    "\n",
    "# identify categorical vs numeric\n",
    "cat_cols = [c for c in X_train.columns if X_train[c].dtype == \"object\"]\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "print(\"num_cols:\", len(num_cols))\n",
    "print(\"cat_cols:\", len(cat_cols))\n",
    "cat_cols[:10], num_cols[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8c3db3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold (from TRAIN) = 0.5000017207945822\n",
      "\n",
      "===== TRAIN =====\n",
      "ROC-AUC: 0.7817\n",
      "PR-AUC : 0.0664\n",
      "Threshold used: 0.500002\n",
      "Confusion matrix:\n",
      "[[656  37]\n",
      " [  3   4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9954    0.9466    0.9704       693\n",
      "           1     0.0976    0.5714    0.1667         7\n",
      "\n",
      "    accuracy                         0.9429       700\n",
      "   macro avg     0.5465    0.7590    0.5685       700\n",
      "weighted avg     0.9865    0.9429    0.9624       700\n",
      "\n",
      "Precision@10: 0.1000\n",
      "Precision@20: 0.0500\n",
      "Precision@50: 0.0800\n",
      "\n",
      "===== TEST =====\n",
      "ROC-AUC: 0.8725\n",
      "PR-AUC : 0.05\n",
      "Threshold used: 0.500002\n",
      "Confusion matrix:\n",
      "[[144   5]\n",
      " [  1   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9931    0.9664    0.9796       149\n",
      "           1     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.9600       150\n",
      "   macro avg     0.4966    0.4832    0.4898       150\n",
      "weighted avg     0.9865    0.9600    0.9731       150\n",
      "\n",
      "Precision@10: 0.0000\n",
      "Precision@20: 0.0500\n",
      "Precision@50: 0.0200\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Preprocess + Model\n",
    "# =========================\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        ]), num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=2000,\n",
    "    class_weight=\"balanced\",\n",
    "    C=0.1,\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "p_train = model.predict_proba(X_train)[:, 1]\n",
    "p_test  = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "\n",
    "def precision_at_k(y, p, k=20):\n",
    "    \"\"\"Assumes y is array-like (numpy array, list, or pandas Series).\"\"\"\n",
    "    y_arr = np.asarray(y)\n",
    "    idx = np.argsort(p)[::-1][:k]\n",
    "    return y_arr[idx].sum() / k\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import numpy as np\n",
    "\n",
    "def find_threshold_for_precision(y, p, target_precision=0.2, min_recall=0.01):\n",
    "    \"\"\"\n",
    "    Pick a threshold that achieves precision >= target_precision AND recall >= min_recall.\n",
    "    Among those, pick the one with the highest recall (more useful than choosing the first).\n",
    "    Falls back to best F1 if no threshold meets constraints.\n",
    "    \"\"\"\n",
    "    precision, recall, thresholds = precision_recall_curve(y, p)\n",
    "\n",
    "    # precision and recall have length n+1, thresholds has length n\n",
    "    # Align thresholds to same length by appending 1.0 (degenerate \"predict none\" point)\n",
    "    thresholds = np.append(thresholds, 1.0)\n",
    "\n",
    "    # Valid candidates must have non-trivial recall and not be the degenerate point\n",
    "    candidates = np.where(\n",
    "        (precision >= target_precision) &\n",
    "        (recall >= min_recall) &\n",
    "        (thresholds < 1.0)\n",
    "    )[0]\n",
    "\n",
    "    if len(candidates) > 0:\n",
    "        # choose the candidate with maximum recall\n",
    "        best = candidates[np.argmax(recall[candidates])]\n",
    "        return thresholds[best]\n",
    "\n",
    "    # Fallback: maximize F1 over non-degenerate thresholds\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "    valid = np.where(thresholds < 1.0)[0]\n",
    "    best = valid[np.nanargmax(f1[valid])]\n",
    "    return thresholds[best]\n",
    "\n",
    "\n",
    "def eval_block(name, y, p, threshold):\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"ROC-AUC:\", round(roc_auc_score(y, p), 4))\n",
    "    print(\"PR-AUC :\", round(average_precision_score(y, p), 4))\n",
    "    pred = (p >= threshold).astype(int)\n",
    "    print(f\"Threshold used: {threshold:.6f}\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y, pred))\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "    for k in [10, 20, 50]:\n",
    "        if k <= len(p):\n",
    "            print(f\"Precision@{k}: {precision_at_k(y, p, k=k):.4f}\")\n",
    "\n",
    "# =========================\n",
    "# Pick threshold on TRAIN\n",
    "# =========================\n",
    "\n",
    "# Choose a target precision that makes sense for your use-case\n",
    "# (try 0.1, 0.2, 0.3, etc.)\n",
    "target_precision = 0.20\n",
    "\n",
    "opt_thresh = find_threshold_for_precision(y_train, p_train, target_precision=target_precision)\n",
    "print(\"Chosen threshold (from TRAIN) =\", opt_thresh)\n",
    "\n",
    "# =========================\n",
    "# Evaluate with that threshold\n",
    "# =========================\n",
    "\n",
    "eval_block(\"TRAIN\", y_train, p_train, threshold=opt_thresh)\n",
    "eval_block(\"TEST\",  y_test,  p_test,  threshold=opt_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc1a94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 recall (TEST): 0.000\n",
      "Top-10 recall (TEST): 0.000\n",
      "Top-20 recall (TEST): 1.000\n",
      "Top-50 recall (TEST): 1.000\n",
      "Top-100 recall (TEST): 1.000\n"
     ]
    }
   ],
   "source": [
    "def topk_recall(y_true, prob, k):\n",
    "    # percent of fraud caught if you investigate top-k highest risk\n",
    "    idx = np.argsort(-prob)[:k]\n",
    "    return y_true.iloc[idx].sum() / max(y_true.sum(), 1)\n",
    "\n",
    "for k in [5, 10, 20, 50, 100]:\n",
    "    r = topk_recall(y_test, p_test, k)\n",
    "    print(f\"Top-{k} recall (TEST): {r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6439d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, p_test)\n",
    "roc = roc_auc_score(y_test, p_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(f\"ROC curve (TEST) | AUC={roc:.3f}\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.show()\n",
    "\n",
    "# PR\n",
    "prec, rec, _ = precision_recall_curve(y_test, p_test)\n",
    "pr = average_precision_score(y_test, p_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rec, prec)\n",
    "plt.title(f\"PR curve (TEST) | AP={pr:.3f}\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()\n",
    "\n",
    "print(\"TEST ROC-AUC:\", roc)\n",
    "print(\"TEST PR-AUC :\", pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ac9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "    \n",
    "    # Use same preprocess (OneHot) -> sparse matrix\n",
    "    Xtr = preprocess.fit_transform(X_train)\n",
    "    Xte = preprocess.transform(X_test)\n",
    "\n",
    "    # scale_pos_weight helps imbalance\n",
    "    pos = (y_train == 1).sum()\n",
    "    neg = (y_train == 0).sum()\n",
    "    spw = neg / max(pos, 1)\n",
    "\n",
    "    lgbm = lgb.LGBMClassifier(\n",
    "        n_estimators=400,\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=31,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=1.0,\n",
    "        scale_pos_weight=spw,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    lgbm.fit(Xtr, y_train)\n",
    "\n",
    "    p_te = lgbm.predict_proba(Xte)[:, 1]\n",
    "    print(\"LightGBM TEST ROC-AUC:\", round(roc_auc_score(y_test, p_te), 4))\n",
    "    print(\"LightGBM TEST PR-AUC :\", round(average_precision_score(y_test, p_te), 4))\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"LightGBM not available or failed:\", repr(e))\n",
    "    print(\"If you want it: pip install lightgbm\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
