{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b83e6b51",
   "metadata": {},
   "source": [
    "# Baseline Model Evaluation (Train → Val → Test)\n",
    "\n",
    "## Selected features (deduplicated best version per feature)\n",
    "| Rank | Feature | Mutual Info (MI) |\n",
    "|---:|---|---:|\n",
    "| 1 | is_international_user | 0.063161 |\n",
    "| 2 | uses_many_channels | 0.016385 |\n",
    "| 3 | industry | 0.011218 |\n",
    "| 4 | kyc_province | 0.006378 |\n",
    "| 5 | recent_amount_ratio | 0.005571 |\n",
    "| 6 | ratio_emt | 0.005094 |\n",
    "| 7 | amount_cv | 0.004436 |\n",
    "| 8 | debit_ratio | 0.004303 |\n",
    "| 9 | channel_entropy | 0.003901 |\n",
    "| 10 | total_amount_vs_finpeer | 0.003895 |\n",
    "| 11 | occupation | 0.003692 |\n",
    "| 12 | pct_history_before_intl | 0.003631 |\n",
    "| 13 | credit_ratio | 0.003352 |\n",
    "| 14 | cv_vs_peer_ratio | 0.003101 |\n",
    "| 15 | max_amount | 0.002908 |\n",
    "\n",
    "**Goal:** Train a baseline classifier (Logistic Regression) on the training split, tune nothing fancy, and measure performance on validation (and final check on test).\n",
    "\n",
    "**Primary metric:** ROC-AUC (accuracy is not meaningful for imbalanced AML).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090befe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "REPO_ROOT = Path.cwd().parents[0]\n",
    "PROCESSED = REPO_ROOT / \"data/processed\"\n",
    "\n",
    "# Uncomment if you haven't loaded them yet:\n",
    "# customers_train = pd.read_csv(PROCESSED/\"customers_train.csv\")\n",
    "# customers_val   = pd.read_csv(PROCESSED/\"customers_val.csv\")\n",
    "# customers_test  = pd.read_csv(PROCESSED/\"customers_test.csv\")\n",
    "# txns_train = pd.read_csv(PROCESSED/\"transactions_train.csv\")\n",
    "# txns_val   = pd.read_csv(PROCESSED/\"transactions_val.csv\")\n",
    "# txns_test  = pd.read_csv(PROCESSED/\"transactions_test.csv\")\n",
    "\n",
    "print(customers_train.shape, customers_val.shape, customers_test.shape)\n",
    "print(txns_train.shape, txns_val.shape, txns_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da7125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\n",
    "    \"is_international_user\",\n",
    "    \"uses_many_channels\",\n",
    "    \"industry\",\n",
    "    \"kyc_province\",\n",
    "    \"recent_amount_ratio\",\n",
    "    \"ratio_emt\",\n",
    "    \"amount_cv\",\n",
    "    \"debit_ratio\",\n",
    "    \"channel_entropy\",\n",
    "    \"total_amount_vs_finpeer\",\n",
    "    \"occupation\",\n",
    "    \"pct_history_before_intl\",\n",
    "    \"credit_ratio\",\n",
    "    \"cv_vs_peer_ratio\",\n",
    "    \"max_amount\",\n",
    "]\n",
    "\n",
    "TARGET = \"label\"\n",
    "IDCOL = \"customer_id\"\n",
    "\n",
    "def make_xy(df: pd.DataFrame, features=FEATURES):\n",
    "    d = df[[IDCOL, TARGET] + [c for c in features if c in df.columns]].copy()\n",
    "\n",
    "    # y must be int\n",
    "    d[TARGET] = pd.to_numeric(d[TARGET], errors=\"coerce\").astype(int)\n",
    "\n",
    "    # separate X/y\n",
    "    X = d.drop(columns=[IDCOL, TARGET])\n",
    "    y = d[TARGET]\n",
    "\n",
    "    # identify categorical vs numeric\n",
    "    cat_cols = [c for c in X.columns if X[c].dtype == \"object\"]\n",
    "    num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "    # fill missing\n",
    "    for c in cat_cols:\n",
    "        X[c] = X[c].fillna(\"Unknown\").astype(str).str.strip()\n",
    "    for c in num_cols:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    return X, y, cat_cols, num_cols\n",
    "\n",
    "X_train, y_train, cat_cols, num_cols = make_xy(customers_train)\n",
    "X_val,   y_val,   _, _ = make_xy(customers_val)\n",
    "X_test,  y_test,  _, _ = make_xy(customers_test)\n",
    "\n",
    "print(\"Categorical:\", cat_cols)\n",
    "print(\"Numeric:\", num_cols)\n",
    "print(\"X_train:\", X_train.shape, \"Positive rate:\", y_train.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "        (\"num\", \"passthrough\", num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "model = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    class_weight=\"balanced\",   # important for imbalanced AML\n",
    "    solver=\"liblinear\"\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, classification_report,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "def eval_split(name, X, y):\n",
    "    proba = clf.predict_proba(X)[:, 1]\n",
    "    pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "    roc = roc_auc_score(y, proba)\n",
    "    ap  = average_precision_score(y, proba)\n",
    "    cm  = confusion_matrix(y, pred)\n",
    "\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(\"ROC-AUC:\", round(roc, 4))\n",
    "    print(\"PR-AUC :\", round(ap, 4))\n",
    "    print(\"Confusion matrix @0.5:\\n\", cm)\n",
    "    print(classification_report(y, pred, digits=4))\n",
    "\n",
    "    return proba\n",
    "\n",
    "p_train = eval_split(\"TRAIN\", X_train, y_train)\n",
    "p_val   = eval_split(\"VAL\",   X_val,   y_val)\n",
    "p_test  = eval_split(\"TEST\",  X_test,  y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d5a5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "proba = p_val\n",
    "thresholds = np.linspace(0.01, 0.99, 99)\n",
    "\n",
    "best_t, best_f1 = None, -1\n",
    "for t in thresholds:\n",
    "    pred = (proba >= t).astype(int)\n",
    "    f1 = f1_score(y_val, pred)\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_t = f1, t\n",
    "\n",
    "print(\"Best threshold on VAL (max F1):\", round(best_t, 3), \"F1:\", round(best_f1, 4))\n",
    "\n",
    "# evaluate test at this threshold\n",
    "pred_test = (p_test >= best_t).astype(int)\n",
    "print(\"\\nTEST report @best_val_threshold\")\n",
    "print(classification_report(y_test, pred_test, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8592425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names after one-hot\n",
    "ohe = clf.named_steps[\"prep\"].named_transformers_[\"cat\"]\n",
    "cat_feature_names = ohe.get_feature_names_out(cat_cols)\n",
    "\n",
    "all_feature_names = np.concatenate([cat_feature_names, np.array(num_cols, dtype=str)])\n",
    "\n",
    "coefs = clf.named_steps[\"model\"].coef_.ravel()\n",
    "coef_df = pd.DataFrame({\"feature\": all_feature_names, \"coef\": coefs})\n",
    "coef_df[\"abs_coef\"] = coef_df[\"coef\"].abs()\n",
    "coef_df = coef_df.sort_values(\"abs_coef\", ascending=False)\n",
    "\n",
    "coef_df.head(25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de22cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_val, p_val)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0,1], [0,1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Validation)\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
